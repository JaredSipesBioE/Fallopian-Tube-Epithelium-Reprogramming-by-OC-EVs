---
title: "qc_and_normalization"
author: "Jared Sipes"
date: "2025-04-24"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Summary

This is the first document in the project. (For a table of contents, sea Readme)

This file contains the preliminary QC, Filtering, and Normalization of the GeoMx Dataset. 

The functions used to create **Supplemental Figure 2** are included in this file. 

All analysis follows the Bioconductor vignette:

[Analyzing GeoMx-NGS RNA Expression Data with GeomxTools (bioconductor.org)](https://www.bioconductor.org/packages/release/workflows/vignettes/GeoMxWorkflows/inst/doc/GeomxTools_RNA-NGS_Analysis.html#5_Normalization)


## 1. Load Required Packages

```{r}
# #
# if (!require("BiocManager", quietly = TRUE))
#     install.packages("BiocManager")
# # 
# # # The following initializes most up to date version of Bioc
# BiocManager::install()
# 
# BiocManager::install("NanoStringNCTools")
# BiocManager::install("GeomxTools")
# BiocManager::install("GeoMxWorkflows")

# Note:
# Needed to install package lme4, numderiv
library(NanoStringNCTools)
library(GeomxTools)
library(GeoMxWorkflows)

if(packageVersion("GeomxTools") < "2.1" & 
   packageVersion("GeoMxWorkflows") >= "1.0.1"){
    stop("GeomxTools and Workflow versions do not match. Please use the same version. 
    This workflow is meant to be used with most current version of packages. 
    If you are using an older version of Bioconductor please reinstall GeoMxWorkflows and use vignette(GeoMxWorkflows) instead")
}

if(packageVersion("GeomxTools") > "2.1" & 
   packageVersion("GeoMxWorkflows") <= "1.0.1"){
    stop("GeomxTools and Workflow versions do not match. 
         Please use the same version, see install instructions above.")
    
    # to remove current package version
        # remove.packages("GeomxTools")
        # remove.packages("GeoMxWorkflows")
    # see install instructions above 
}
```

Other packages used in the Notebook are listed below. 

```{r}
# List of required packages
# packages <- c(
#   "knitr", "tidyverse", "dplyr", "ggforce", "writexl",
#   "janitor", "readxl", "cowplot", "patchwork"
# )
# 
# # Install missing packages
# installed <- packages %in% rownames(installed.packages())
# if (any(!installed)) {
#   install.packages(packages[!installed])
# }


library(knitr)
library(tidyverse)
library(dplyr)
library(ggforce)
library(writexl)
library(janitor)
library(readxl)
library(cowplot)

library(patchwork)

```


#2. Load Files

We need three different types of files to create the initial dataset, plus one for when you are doing this for the first time.

1.   DCCs files -- these contain the expression count data and some info about sequencing data from the next gen sequencing platform used.

2.   PKCs -- the probe assay metadata, which describes which gene targets are present in the data, find at the following link: [GeoMx DSP Configuration Files \| NanoString⁤](https://nanostring.com/products/geomx-digital-spatial-profiler/geomx-dsp-configuration-files/)

    (Do not bother to unzip, place in the appropriate file as is.)

3.   Annotation file - this will contain information about the tissue, segment area and nuclei count, and any other info you choose to provide.


```{r}

# Reference the main folder 'file.path' containing the sub-folders with each
# data file type:

datadir <- file.path(paste0(getwd(), "/data_input"))

# automatically list files in each directory for use
DCCFiles <- dir(file.path(datadir, "dccs"), pattern = "*.dcc",
                full.names = TRUE, recursive = TRUE)


PKCFiles <- dir(file.path(datadir, "pkcs"), pattern = ".pkc$",
                                full.names = TRUE, recursive = TRUE)


# Make sure to add correct annotation file
SampleAnnotationFile <- 
    dir(file.path(datadir, "annotation"), pattern = "4-24-25.xlsx$",
        full.names = TRUE, recursive = TRUE)


```



Testing creation of `readNanoStringGeoMxSet` object. If you get errors saying files are missing or do not have any count info, check to make sure all .dcc files are in the folder (and that you have copied the correct ones).

```{r}


#load data

allGeoMx <-
    readNanoStringGeoMxSet(dccFiles = DCCFiles,
                           pkcFiles = PKCFiles,
                           phenoDataFile = SampleAnnotationFile,
                           phenoDataSheet = "Sheet1", # make sure this matches doc
                           phenoDataDccColName = "Sample_ID",
                           protocolDataColNames = c("Aoi", "Roi"),
                           experimentDataColNames = c("Panel"))

# Potential Errors:
# Error in .subset2(x, i, exact = exact) : subscript out of bounds
# Check Traceback
# If traceback goes to pheno[[nucleiCol]]
# check the naming of nuclei columns -- should have only one! 

```

Check size of object, make sure there are no files from other experiments present. 

Both outputs should have a sample size of 614. 

```{r}

dim(allGeoMx)

dataEV <- allGeoMx[, allGeoMx$Experiment == "EVTreat"]

dim(dataEV)


```

Check PKC files (Hs_R_NGS_CTA_v1.0.pkc)


```{r}

# make sure you loaded knitr using library(knitr)

pkcs <- annotation(dataEV)
modules <- gsub(".pkc", "", pkcs)
kable(data.frame(PKCs = pkcs, modules = modules))

```


Subset the data into 1-day and 14-day datasets.

```{r}
dataEV_D14 <- dataEV[, pData(dataEV)$Days == "14-Day"]

dataEV_D01 <- dataEV[, pData(dataEV)$Days == "1-Day"]
```



3. Sample Overview

Now that we have loaded the data, we can visually summarize the experimental design for our dataset to look at the different types of samples and ROI/AOI segments that have been profiled. We present this information in a Sankey diagram.

```{r}

# select the annotations we want to show, use `` to surround column names with
# spaces or special symbols
count_mat <- dplyr::count(pData(dataEV), Tissue, Patient, Treatment, Days, Segment)



# gather the data and plot in order: region, segment
test_gr <- gather_set_data(count_mat, 1:3)
# test_gr$x <- factor(test_gr$x,
#                     levels = c("patient_number", region", "segment"))
```




## FUNCT: plot_sankey

```{r fig.height=10, fig.width=10, Sankey_PreQC}
plot_sankey <- function(count_mat){
  
  test_gr <- gather_set_data(count_mat, 1:3)
  
  ggplot(test_gr, aes(x, id = id, split = y, value = n)) +
    geom_parallel_sets(aes(fill = Segment), alpha = 0.5, axis.width = 0.1) +
    geom_parallel_sets_axes(axis.width = 0.2) +
    geom_parallel_sets_labels(color = "white", size = 5) +
    theme_classic(base_size = 20) +
    theme(legend.position = "bottom",
          axis.ticks.y = element_blank(),
          axis.line = element_blank(),
          axis.text.y = element_blank()) +
    scale_y_continuous(expand = expansion(0)) +
    scale_x_discrete(expand = expansion(0)) +
    labs(x = "", y = "") +
    annotate(geom = "segment", x = 3.3, xend = 3.3,
             y = 0, yend = 100, lwd = 2) +
    annotate( "text", x = 3.2, y = 30, angle = 90, size = 5,
             hjust = 0.1, label = paste0(sum(count_mat$n), "segments"))
  
}

```


```{r fig.height=20, fig.width=20}

Sankey_All <- plot_sankey(count_mat = dplyr::count(pData(dataEV), Patient, Treatment, Days, Segment))


Sankey_D14 <- plot_sankey(count_mat = dplyr::count(pData(dataEV_D14), Patient, Treatment, Segment))


Sankey_D1 <- plot_sankey(count_mat = dplyr::count(pData(dataEV_D01), Patient, Treatment, Segment))

Sankey_All | (Sankey_D1 / Sankey_D14)


```

# 4. QC and Pre-processing

There are three sets of pre-process workflow for GeoMx data. In the first part, faulty segments are removed and genes are selected based on Quality Control.

First, however, we must shift all counts of 0 to 1 (this permits downstream transformations.

```{r}


# shift counts to one

dataEV <- shiftCountsOne(dataEV, useDALogic = TRUE)

```


## 4.1 Select Segment QC

First, we select the QC parameter cutoffs, against which our ROI/AOI segments will be tested and flagged appropriately. We have selected the appropriate study-specific parameters for this study. Note: the default QC values recommended above are advised when surveying a new dataset for the first time.

For some reason the QC Summary seems not to be working properly for low area? Possibly the area got dropped from the annotations somehow? But areas seems to be there based on a check?


```{r}

# Default QC cutoffs are commented in () adjacent to the respective parameters
# study-specific values were selected after visualizing the QC results in more
# detail below

QC_params <-
    list(minSegmentReads = 1000, # Minimum number of reads (1000)
         percentTrimmed = 80,    # Minimum % of reads trimmed (80%)
         percentStitched = 5,   # Minimum % of reads stitched (80%)
         percentAligned = 5,    # Minimum % of reads aligned (80%)
         percentSaturation = 50, # Minimum sequencing saturation (50%)
         minNegativeCount = 1,   # Minimum negative control counts (10)
         maxNTCCount = 1000,     # Maximum counts observed in NTC well (1000)
         minNuclei = 20,         # Minimum # of nuclei estimated (100)
         minArea = 1000)         # Minimum segment area (5000)
dataEV <-
    setSegmentQCFlags(dataEV, 
                      qcCutoffs = QC_params)        

# Collate QC Results
QCResults <- protocolData(dataEV)[["QCFlags"]]
  # this seems to generate some NA values for the NTc controls, which don't have area. 
  # Tell it to ignore NAs? Or drop NTC controls?


flag_columns <- colnames(QCResults)
QC_Summary <- data.frame(Pass = colSums(!QCResults[, flag_columns], na.rm = TRUE),
                         Warning = colSums(QCResults[, flag_columns], na.rm = TRUE))
QCResults$QCStatus <- apply(QCResults, 1L, function(x) {
    ifelse(sum(x) == 0L, "PASS", "WARNING")
})
QC_Summary["TOTAL FLAGS", ] <-
    c(sum(QCResults[, "QCStatus"] == "PASS", na.rm = TRUE),
      sum(QCResults[, "QCStatus"] == "WARNING", na.rm = TRUE))

```

## 4.2 Visualize Segment QC

Before excluding any low-performing ROI/AOI segments, we visualize the distributions of the data for the different QC parameters. Note that the "Select Segment QC" and "Visualize Segment QC" sections are performed in parallel to fully understand low-performing segments for a given study. Iteration may follow to select the study-specific QC cutoffs.

For QC visualization, we write a quick function to draw histograms of our data.

```{r}



# Graphical summaries of QC statistics plot function
QC_histogram <- function(assay_data = NULL,
                         annotation = NULL,
                         fill_by = NULL,
                         thr = NULL,
                         scale_trans = NULL) {
    plt <- ggplot(assay_data,
                  aes_string(x = paste0("unlist(`", annotation, "`)"),
                             fill = fill_by)) +
        geom_histogram(bins = 50) +
        geom_vline(xintercept = thr, lty = "dashed", color = "black") +
        theme_bw() + guides(fill = "none") +
        facet_wrap(as.formula(paste("~", fill_by)), nrow = 4) +
        labs(x = annotation, y = "Number of Segments", title = annotation)
    if(!is.null(scale_trans)) {
        plt <- plt +
            scale_x_continuous(trans = scale_trans)
    }
    plt
}

```

Now we explore each of the QC metrics for the segments.



```{r fig.height=5, fig.width=8}

col_by <- "Days"

trimmed <- QC_histogram(sData(dataEV), "Trimmed (%)", col_by, 80)
stitched <- QC_histogram(sData(dataEV), "Stitched (%)", col_by, 5)
aligned <- QC_histogram(sData(dataEV), "Aligned (%)", col_by, 5)
saturated <- QC_histogram(sData(dataEV), "Saturated (%)", col_by, 50) +
    labs(title = "Sequencing Saturation (%)",
         x = "Sequencing Saturation (%)")
AreaHist <- QC_histogram(sData(dataEV), "Area", col_by, 1000, scale_trans = "log10")
NucleiHist <- QC_histogram(sData(dataEV), "nuclei", col_by, 20)

QC_metrics_by_day <- plot_grid(trimmed, stitched, aligned, saturated, AreaHist, NucleiHist)

QC_metrics_by_day

```


```{r fig.height=5, fig.width=8}


change_colors <- function(plot){
  plot <- plot +
  scale_fill_manual(values = c("Ciliated" = "green",
                                "Secretory" ="red") )
  return(plot)
}

col_by <- "segment"

trimmed <- QC_histogram(sData(dataEV), "Trimmed (%)", col_by, 80) |> change_colors()
stitched <- QC_histogram(sData(dataEV), "Stitched (%)", col_by, 5) |> change_colors()
aligned <- QC_histogram(sData(dataEV), "Aligned (%)", col_by, 5)|> change_colors()
saturated <- (QC_histogram(sData(dataEV), "Saturated (%)", col_by, 50) +
    labs(title = "Sequencing Saturation (%)",
         x = "Sequencing Saturation (%)") ) |> change_colors()
AreaHist <- QC_histogram(sData(dataEV), "Area", col_by, 1000, scale_trans = "log10")|> change_colors()
NucleiHist <- QC_histogram(sData(dataEV), "nuclei", col_by, 20) |> change_colors()

QC_metrics_by_seg <- plot_grid(trimmed, stitched, aligned, saturated, AreaHist, NucleiHist)

QC_metrics_by_seg

```


```{r}
# calculate the negative geometric means for each module
negativeGeoMeans <- 
    esBy(negativeControlSubset(dataEV), 
         GROUP = "Module", 
         FUN = function(x) { 
             assayDataApply(x, MARGIN = 2, FUN = ngeoMean, elt = "exprs") 
         }) 
protocolData(dataEV)[["NegGeoMean"]] <- negativeGeoMeans

# explicitly copy the Negative geoMeans from sData to pData
negCols <- paste0("NegGeoMean_", modules)
pData(dataEV)[, negCols] <- sData(dataEV)[["NegGeoMean"]]
for(ann in negCols) {
    plt <- QC_histogram(pData(dataEV), ann, col_by, 2, scale_trans = "log10")
    print(plt)
}

```

```{r fig.height=10, fig.width=20}

col_by <- "Days"

raw <- QC_histogram(sData(dataEV), "Raw", col_by, 80)

raw

```


```{r}
# detach neg_geomean columns ahead of aggregateCounts call
pData(dataEV) <- pData(dataEV)[, !colnames(pData(dataEV)) %in% negCols]

# show all NTC values, Freq = # of Segments with a given NTC count:

# we seem to be missing a column called NTC that is required for this to work 
kable(table(NTC_Count = sData(dataEV)$NTC),
      col.names = c("NTC Count", "# of Segments"))

```


```{r}

kable(QC_Summary, caption = "QC Summary Table for each Segment")


```


# 4.3 Remove Flagged Segments

As the final step in the QC, we remove all flagged segments that do not meet the QC cutoff.

```{r}
dataEV <- dataEV[, QCResults$QCStatus == "PASS"]

# Subsetting our dataset has removed samples which did not pass QC

dim(dataEV)


```




# 5. Probe QC

Before we summarize our data into gene-level count data, we will remove low-performing probes. In short, this QC is an outlier removal process, whereby probes are either removed entirely from the study (global) or from specific segments (local). The QC applies to gene targets for which there are multiple distinct probes representing the count for a gene per segment. In WTA data, one specific probe exists per target gene; thus, Probe QC does not apply to the endogenous genes in the panel. Rather, it is performed on the negative control probes; there are multiple probes representing our negative controls, which do not target any sequence in the genome. These probes enable calculation of the background per segment and will be important for determining gene detection downstream.

After Probe QC, there will always remain at least one probe representing every gene target. In other words, Probe QC never removes genes from your data.

## 5.1 Set Probe QC Flags

A probe is removed globally from the dataset if either of the following is true:

-   the geometric mean of that probe's counts from all segments divided by the geometric mean of all probe counts representing the target from all segments is less than 0.1
-   the probe is an outlier according to the Grubb's test in at least 20% of the segments A probe is removed locally (from a given segment) if the probe is an outlier according to the Grubb's test in that segment.

We do not typically adjust these QC parameters.


```{r}


# Generally keep the qcCutoffs parameters unchanged. Set removeLocalOutliers to 
# FALSE if you do not want to remove local outliers
dataEV <- setBioProbeQCFlags(dataEV, 
                               qcCutoffs = list(minProbeRatio = 0.1,
                                                percentFailGrubbs = 20), 
                               removeLocalOutliers = TRUE)

ProbeQCResults <- fData(dataEV)[["QCFlags"]]

# Define QC table for Probe QC
qc_df <- data.frame(Passed = sum(rowSums(ProbeQCResults[, -1]) == 0),
                    Global = sum(ProbeQCResults$GlobalGrubbsOutlier),
                    Local = sum(rowSums(ProbeQCResults[, -2:-1]) > 0
                                & !ProbeQCResults$GlobalGrubbsOutlier))

```


We report the number of global and local outlier probes.


```{r}

qc_df


```



## 5.2 Exclude Outlier Probes

```{r}
#Subset object to exclude all that did not pass Ratio & Global testing
ProbeQCPassed <- 
    subset(dataEV, 
           fData(dataEV)[["QCFlags"]][,c("LowProbeRatio")] == FALSE &
               fData(dataEV)[["QCFlags"]][,c("GlobalGrubbsOutlier")] == FALSE)
dim(ProbeQCPassed)
#> Features  Samples 
#>    18641      229
dataEV <- ProbeQCPassed 


```





## 5.3 Create Gene Level Count Data

With our Probe QC steps complete, we will generate a gene-level count matrix. The count for any gene with multiple probes per segment is calculated as the geometric mean of those probes.

```{r}

# Check how many unique targets the object has
length(unique(featureData(dataEV)[["TargetName"]]))


# collapse to targets
target_dataEV <- aggregateCounts(dataEV)
dim(target_dataEV)
#> Features  Samples 
#>    18504      229
exprs(target_dataEV)[1:5, 1:2]



```



## 5.4 Limit of Quantitation

In addition to Segment and Probe QC, we also determine the limit of quantification (LOQ) per segment. The LOQ is calculated based on the distribution of negative control probes and is intended to approximate the quantifiable limit of gene expression per segment. Please note that this process is more stable in larger segments. Likewise, the LOQ may not be as accurately reflective of true signal detection rates in segments with low negative probe counts (ex: \<2). The formula for calculating the LOQ in the ith segment is:

$$LOQ_i=geomean(NegProbe_i)∗geoSD(NegProbe_i)^n$$

We typically use 2 geometric standard deviations (n=2) above the geometric mean as the LOQ, which is reasonable for most studies. We also recommend that a minimum LOQ of 2 be used if the LOQ calculated in a segment is below this threshold.


```{r}

# Define LOQ SD threshold and minimum value
cutoff <- 2
minLOQ <- 2

# Calculate LOQ per module tested
LOQ <- data.frame(row.names = colnames(target_dataEV))
for(module in modules) {
    vars <- paste0(c("NegGeoMean_", "NegGeoSD_"),
                   module)
    if(all(vars[1:2] %in% colnames(pData(target_dataEV)))) {
        LOQ[, module] <-
            pmax(minLOQ,
                 pData(target_dataEV)[, vars[1]] * 
                     pData(target_dataEV)[, vars[2]] ^ cutoff)
    }
}
pData(target_dataEV)$LOQ <- LOQ


```


## 5.5 Filtering

After determining the limit of quantification (LOQ) per segment, we recommend filtering out either segments and/or genes with abnormally low signal. Filtering is an important step to focus on the true biological data of interest.

We determine the number of genes detected in each segment across the dataset.


```{r}

LOQ_Mat <- c()
for(module in modules) {
    ind <- fData(target_dataEV)$Module == module
    Mat_i <- t(esApply(target_dataEV[ind, ], MARGIN = 1,
                       FUN = function(x) {
                           x > LOQ[, module]
                       }))
    LOQ_Mat <- rbind(LOQ_Mat, Mat_i)
}
# ensure ordering since this is stored outside of the geomxSet
LOQ_Mat <- LOQ_Mat[fData(target_dataEV)$TargetName, ]


```


## 5.6 Segment Gene Detection

We first filter out segments with exceptionally low signal. These segments will have a small fraction of panel genes detected above the LOQ relative to the other segments in the study. Let's visualize the distribution of segments with respect to their % genes detected:

```{r fig.height=10, fig.width=20}

library(patchwork)

# Save detection rate information to pheno data
pData(target_dataEV)$GenesDetected <- 
    colSums(LOQ_Mat, na.rm = TRUE)
pData(target_dataEV)$GeneDetectionRate <-
    pData(target_dataEV)$GenesDetected / nrow(target_dataEV)

# Determine detection thresholds: 1%, 5%, 10%, 15%, >15%
pData(target_dataEV)$DetectionThreshold <- 
    cut(pData(target_dataEV)$GeneDetectionRate,
        breaks = c(0, 0.01, 0.05, 0.1, 0.15, 0.20, 0.25, 1),
        labels = c("<1%", "1-5%", "5-10%", "10-15%", "16%-20%", "21%-25%", ">25%"))

# stacked bar plot of different cut points (1%, 5%, 10%, 15%)
a<- ggplot(pData(target_dataEV),
       aes(x = DetectionThreshold)) +
    geom_bar(aes(fill = plate)) +
    geom_text(stat = "count", aes(label = ..count..), vjust = -0.5) +
    theme_bw() +
    scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
    labs(x = "Gene Detection Rate",
         y = "Segments, #",
         fill = "Segment Type")
#> Warning: The dot-dot notation (`..count..`) was deprecated in ggplot2 3.4.0.
#> ℹ Please use `after_stat(count)` instead.
#> This warning is displayed once every 8 hours.
#> Call `lifecycle::last_lifecycle_warnings()` to see where this warning was
#> generated.


b<- ggplot(pData(target_dataEV),
       aes(x = DetectionThreshold)) +
    geom_bar(aes(fill = Segment)) +
    geom_text(stat = "count", aes(label = ..count..), vjust = -0.5) +
    theme_bw() +
    scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
    labs(x = "Gene Detection Rate",
         y = "Segments, #",
         fill = "Segment Type")


c <- ggplot(pData(target_dataEV),
       aes(x = DetectionThreshold)) +
    geom_bar(aes(fill = Patient)) +
    geom_text(stat = "count", aes(label = ..count..), vjust = -0.5) +
    theme_bw() +
    scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
    labs(x = "Gene Detection Rate",
         y = "Segments, #",
         fill = "Segment Type")

d <- ggplot(pData(target_dataEV),
       aes(x = DetectionThreshold)) +
    geom_bar(aes(fill = Days)) +
    geom_text(stat = "count", aes(label = ..count..), vjust = -0.5) +
    theme_bw() +
    scale_y_continuous(expand = expansion(mult = c(0, 0.1))) +
    labs(x = "Gene Detection Rate",
         y = "Segments, #",
         fill = "Segment Type")


a + b+ c + d

```


```{r}

# cut percent genes detected from above
kable(table(pData(target_dataEV)$DetectionThreshold,
            pData(target_dataEV)$Segment))

kable(table(pData(target_dataEV)$DetectionThreshold,
            pData(target_dataEV)$Days))


kable(table(pData(target_dataEV)$DetectionThreshold,
            pData(target_dataEV)$Patient))

```




In this example, we choose to remove segments with less than 5% of the genes detected. Generally, 5-10% detection is a reasonable segment filtering threshold. However, based on the experimental design (e.g. segment types, size, nuclei) and tissue characteristics (e.g. type, age), these guidelines may require adjustment.

```{r}
target_dataEV <-
    target_dataEV[, pData(target_dataEV)$GeneDetectionRate >= .05]

dim(target_dataEV)
#> Features  Samples 
#>    1812    407

```


Let's re-plot the Sankey diagram showing our current working dataset. This is now a dataset that no longer contains segments flagged by Segment QC or that have low gene detection rates.


```{r}

# select the annotations we want to show, use `` to surround column names with
# spaces or special symbols
count_mat <- dplyr::count(pData(target_dataEV), Tissue, Patient, Treatment, Days, Segment)

write_xlsx(count_mat, "C:/Users/j789s948/Documents/GeoMx Data Analysis/1. EV Treatment of FT Analysis/count_mat_test_2.xlsx")


# gather the data and plot in order: region, segment
test_gr <- gather_set_data(count_mat, 1:3)
# test_gr$x <- factor(test_gr$x,
#                     levels = c("patient_number", region", "segment"))
```

```{r fig.height=10, fig.width=10}
# plot Sankey

ggplot(test_gr, aes(x, id = id, split = y, value = n)) +
    geom_parallel_sets(aes(fill = Segment), alpha = 0.5, axis.width = 0.1) +
    geom_parallel_sets_axes(axis.width = 0.2) +
    geom_parallel_sets_labels(color = "white", size = 4) +
    theme_classic(base_size = 17) + 
    theme(legend.position = "bottom",
          axis.ticks.y = element_blank(),
          axis.line = element_blank(),
          axis.text.y = element_blank()) +
    scale_y_continuous(expand = expansion(0)) + 
    scale_x_discrete(expand = expansion(0)) +
    labs(x = "", y = "") +
    annotate(geom = "segment", x = 3.3, xend = 3.3,
             y = 0, yend = 100, lwd = 2) +
    annotate(geom = "text", x = 3.2, y = 50, angle = 90, size = 5,
             hjust = 0.5, label = paste0(sum(count_mat$n), "segments"))

```



```{r}

dataEV_postfilter <- target_dataEV
# 
# save(dataEV_postfilter, file = "dataEV_postfilter.Rdata")
```


### 4.5.2 Gene Detection Rate.

Next, we determine the detection rate for genes across the study. To illustrate this idea, we create a small gene list (goi) to review.

```{r}
library(scales) # for percent

# Calculate detection rate:
LOQ_Mat <- LOQ_Mat[, colnames(target_dataEV)]
fData(target_dataEV)$DetectedSegments <- rowSums(LOQ_Mat, na.rm = TRUE)
fData(target_dataEV)$DetectionRate <-
    fData(target_dataEV)$DetectedSegments / nrow(pData(target_dataEV))

# Gene of interest detection table
goi <- c("KRT18", "CCL2",
         "FOXJ1", "PAX8", "LGR5")
goi_df <- data.frame(
    Gene = goi,
    Number = fData(target_dataEV)[goi, "DetectedSegments"],
    DetectionRate = percent(fData(target_dataEV)[goi, "DetectionRate"]))



```

```{r}

goi_df


```

We can see that individual genes are detected to varying degrees in the segments, which leads us to the next QC we will perform across the dataset.


### 4.5.3 Gene Filtering

We will graph the total number of genes detected in different percentages of segments. Based on the visualization below, we can better understand global gene detection in our study and select how many low detected genes to filter out of the dataset. Gene filtering increases performance of downstream statistical tests and improves interpretation of true biological signal.


```{r}

# Plot detection rate:
plot_detect <- data.frame(Freq = c(1, 5, 10, 20, 30, 50))
plot_detect$Number <-
    unlist(lapply(c(0.01, 0.05, 0.1, 0.2, 0.3, 0.5),
                  function(x) {sum(fData(target_dataEV)$DetectionRate >= x)}))
plot_detect$Rate <- plot_detect$Number / nrow(fData(target_dataEV))
rownames(plot_detect) <- plot_detect$Freq

gene_segment_plot <- ggplot(plot_detect, aes(x = as.factor(Freq), y = Rate, fill = Rate)) +
    geom_bar(stat = "identity") +
    geom_text(aes(label = formatC(Number, format = "d", big.mark = ",")),
              vjust = 1.6, color = "black", size = 4) +
    scale_fill_gradient2(low = "orange2", mid = "lightblue",
                         high = "dodgerblue3", midpoint = 0.65,
                         limits = c(0,1),
                         labels = scales::percent) +
    theme_bw() +
    scale_y_continuous(labels = scales::percent, limits = c(0,1),
                       expand = expansion(mult = c(0, 0))) +
    labs(x = "% of Segments",
         y = "Genes Detected, % of Panel > LOQ")

gene_segment_plot
```
We typically set a % Segment cutoff ranging from 5-20% based on the biological diversity of our dataset. For this study, we will select 10% as our cutoff. In other words, we will focus on the genes detected in at least 10% of our segments; we filter out the remainder of the targets.

Note: if we know that a key gene is represented in only a small number of segments (\<10%) due to biological diversity, we may select a different cutoff or keep the target gene by manually selecting it for inclusion in the data object.


```{r}

# Subset to target genes detected in at least 10% of the samples.
#   Also manually include the negative control probe, for downstream use
negativeProbefData <- subset(fData(target_dataEV), CodeClass == "Negative")
neg_probes <- unique(negativeProbefData$TargetName)
target_dataEV <- 
    target_dataEV[fData(target_dataEV)$DetectionRate >= 0.1 |
                        fData(target_dataEV)$TargetName %in% neg_probes, ]
dim(target_dataEV)
#> Features  Samples 
#>    10131      221

# retain only detected genes of interest
goi <- goi[goi %in% rownames(target_dataEV)]


```

# 5.9 Export exprs and Annotation Data

```{r}

# library(openxlsx)
# 
# 
# print_TargetCountMatrix <- function(matrix = NULL, file_path = ""){
#   wb <- createWorkbook()
#   addWorksheet(wb, sheetName = "TargetCountMatrix")
#   
#   
#   writeData(wb, sheet = "TargetCountMatrix", x = matrix, 
#             colNames = TRUE, rowNames = TRUE)
#   
#   writeData(wb, sheet = "TargetCountMatrix", x = "TargetName", startCol = 1, startRow = 1)
#   
#   # Save the workbook to an Excel file
#   saveWorkbook(wb, file = file_path, overwrite = TRUE)
# }
# 
# 
# print_anat_comp_annotations <- function(data = NULL,  file_path = ""){
#   col_to_export = c("Days", "Slide.Name", "Segment", "Patient", "Treatment")
#   
#   df_to_export <- pData(data)[, col_to_export]
#   
#   write.xlsx(df_to_export, file_path, rowNames = TRUE, colNames = TRUE)
# }

```



```{r}

# Exprs_df <- exprs(target_dataEV)
# 
# 
# print_TargetCountMatrix(matrix = Exprs_df, file_path = "C:/Users/j789s948/Downloads/Exprs_dataEV_0.05_filter.xlsx")
# 
# # Annotation_df <- pdata(target_dataEV)
# 
# print_anat_comp_annotations(target_dataEV, "C:/Users/j789s948/Downloads/Annotation_dataEV_0.05_filter.xlsx")

```



# 5 Normalization

We will now normalize the GeoMx data for downstream visualizations and differential expression. The two common methods for normalization of DSP-NGS RNA data are i) quartile 3 (Q3) or ii) background normalization.

Both of these normalization methods estimate a normalization factor per segment to bring the segment data distributions together. More advanced methods for normalization and modeling are under active development. However, for most studies, these methods are sufficient for understanding differences between biological classes of segments and samples.

Q3 normalization is typically the preferred normalization strategy for most DSP-NGS RNA studies. Given the low negative probe counts in this particular dataset as shown during Segment QC, we would further avoid background normalization as it may be less stable.

Before normalization, we will explore the relationship between the upper quartile (Q3) of the counts in each segment with the geometric mean of the negative control probes in the data. Ideally, there should be a separation between these two values to ensure we have stable measure of Q3 signal. If you do not see sufficient separation between these values, you may consider more aggressive filtering of low signal segments/genes.

```{r}

quantileNorm <- function(object, toElt = "exprs_norm", fromElt = "exprs"){
  # generate a new object with just relevant expression data
  # exprs_data <- exprs(object)
  
  #rank each item in the object (1 for first expression level, 2 for second, etc.)
  assayDataElement(object, "rank" , validate = TRUE) <- apply(assayDataElement(object, "exprs"),2,rank,ties.method="min")
  
  # #sort based on expression level
  assayDataElement(object, "data_sorted" , validate = TRUE) <- apply(assayDataElement(object, "exprs"), 2, sort)

  # find the mean for each row in the sorted_data
  data_mean <- apply(assayDataElement(object, "data_sorted"), 1, mean)


  index_to_mean <- function(my_index, my_mean)
  {
    return(my_mean[my_index])
  }


  # for each ranked data column, for each number (n) in that column, 
  # apply to it the (nth) mean in the data_mean list
  assayDataElement(object, toElt, validate = TRUE) <- apply(assayDataElement(object, "rank"), 2, index_to_mean, my_mean=data_mean)
  

  return(object)
}
```

Quantile normalization function leonidas


```{r}


quantile_normalization <- function(data, filename, write_to_excel = FALSE){
  data_col_removed <- data[1:nrow(data),-1]
  data_rank <- apply(data_col_removed,2,rank,ties.method="min")
  data_sorted <- data.frame(apply(data_col_removed, 2, sort))
  data_mean <- apply(data_sorted, 1, mean)
  
  index_to_mean <- function(my_index, my_mean)
  {
    return(my_mean[my_index])
  }
  
  data_final <- as.data.frame(apply(data_rank, 2, index_to_mean, my_mean=data_mean))
  rownames(data_final) <- rownames(data_col_removed)
  data_final <- data.frame(data[,1], data_final)
  
  if (write_to_excel) {
    write_xlsx(data_final, path = filename)
    message("Quantile normalized data written to Excel file: ", filename)
  }
  colnames(data_final)[2:ncol(data_final)] <- rep(1:(ncol(data_final)-1))
  return(data_final)
}
```

```{r}

EV_q_norm <- quantileNorm(target_dataEV, toElt = "q_norm")

```


##5.1 Analysis of Normalization


```{r}

library(reshape2)  # for melt
library(cowplot)   # for plot_grid

# Graph Q3 value vs negGeoMean of Negatives
ann_of_interest <- "Segment"


# get a list of the negative probe segments 

negativeProbefData <- subset(fData(EV_q_norm), CodeClass == "Negative")
neg_probes <- unique(negativeProbefData$TargetName)


Stat_data <- 
    data.frame(row.names = colnames(exprs(EV_q_norm)),
               Segment = colnames(exprs(EV_q_norm)),
               Annotation = pData(EV_q_norm)[, ann_of_interest],
               Quantile = unlist(apply(exprs(EV_q_norm), 2,
                                 quantile, 0.75, na.rm = TRUE)),
               NegProbe = exprs(EV_q_norm)[neg_probes, ])
Stat_data_m <- melt(Stat_data, measure.vars = c("Quantile", "NegProbe"),
                    variable.name = "Statistic", value.name = "Value")

plt1 <- ggplot(Stat_data_m,
               aes(x = Value, fill = Statistic)) +
    geom_histogram(bins = 40) + theme_bw() +
    scale_x_continuous(trans = "log2") +
    facet_wrap(~Annotation, nrow = 1) + 
    scale_fill_brewer(palette = 3, type = "qual") +
    labs(x = "Counts", y = "Segments, #")

qnorm_v_neg <- ggplot(Stat_data,
               aes(x = NegProbe, y = Quantile, color = Annotation)) +
    geom_abline(intercept = 0, slope = 1, lty = "dashed", color = "darkgray") +
    geom_point() + guides(color = "none") + theme_bw() +
    scale_x_continuous(trans = "log2") + 
    scale_y_continuous(trans = "log2") +
    theme(aspect.ratio = 1) +
    labs(x = "Negative Probe GeoMean, Counts", y = "Quantile Norm Value, Counts")

plt3 <- ggplot(Stat_data,
               aes(x = NegProbe, y = Quantile / NegProbe, color = Annotation)) +
    geom_hline(yintercept = 1, lty = "dashed", color = "darkgray") +
    geom_point() + theme_bw() +
    scale_x_continuous(trans = "log2") + 
    scale_y_continuous(trans = "log2") +
    theme(aspect.ratio = 1) +
    labs(x = "Negative Probe GeoMean, Counts", y = "Quantile/NegProbe Value, Counts")

btm_row <- plot_grid(qnorm_v_neg, plt3, nrow = 1,
                     rel_widths = c(0.43,0.57))
plot_grid(plt1, btm_row, ncol = 1)

```


#6. Summary Figure of QC Analysis 


Plot sequence saturation vs area in a dot plot. 

```{r}

seq_v_area <- ggplot(sData(EV_q_norm),
               aes(x = Area, 
                   y = as.numeric(sData(EV_q_norm)$`Saturated (%)`[, 1])
                   )
       ) +
    geom_point(aes(color = Segment)) + theme_bw() +
    geom_hline(yintercept=50, linetype="dashed", color = "black")+
    labs(x = "Area (um^2)", y = "Sequence Saturation (%)")

# 
#     scale_x_continuous(trans = "log2") +
#     facet_wrap(~Segment, nrow = 1) + 
#     scale_fill_brewer(palette = 3, type = "qual") +
#     labs(x = "Counts", y = "Segments, #")

```




Plot UMAP and TSNE plot of normalized results. 

```{r}
dataEV_D14 <- EV_q_norm[, pData(EV_q_norm)$Days == "14-Day"]

dataEV_D01 <- EV_q_norm[, pData(EV_q_norm)$Days == "1-Day"]
```

```{r}
library(umap)
library(Rtsne)

# update defaults for umap to contain a stable random_state (seed)
custom_umap <- umap::umap.defaults
custom_umap$random_state <- 42
# run UMAP
umap_out <-
    umap(t(log2(assayDataElement(EV_q_norm , elt = "q_norm"))),  
         config = custom_umap)
#> Found more than one class "dist" in cache; using the first, from namespace 'BiocGenerics'
#> Also defined by 'spam'
pData(EV_q_norm)[, c("UMAP1", "UMAP2")] <- umap_out$layout[, c(1,2)]
ggplot(pData(EV_q_norm),
       aes(x = UMAP1, y = UMAP2, color = Patient, shape = Segment)) +
    geom_point(size = 3) +
    theme_bw()
```

```{r}

# run tSNE
set.seed(42) # set the seed for tSNE as well
tsne_out <-
    Rtsne(t(log2(assayDataElement(dataEV_D01 , elt = "q_norm"))),
          perplexity = ncol(dataEV_D01)*.15)
pData(dataEV_D01)[, c("tSNE1", "tSNE2")] <- tsne_out$Y[, c(1,2)]


tsne_day1_patient <- ggplot(pData(dataEV_D01),
       aes(x = tSNE1, y = tSNE2, color = Patient, shape = Segment)) +
    geom_point(size = 3) +
    theme_bw()

tsne_day1_treatment <- ggplot(pData(dataEV_D01),
       aes(x = tSNE1, y = tSNE2, color = Treatment, shape = Segment)) +
    geom_point(size = 3) +
    theme_bw()



tsne_day1_patient

tsne_day1_treatment

```


# &. Supplemental Figure 2

The output for Supplemental Figure 2 is generated below


```{r Supplemental Fig 2, fig.height=10, fig.width=20}

(QC_metrics_by_day + ggtitle("Quality Controls Cutoffs 1-day and 14-day treatment comparison") | 
   QC_metrics_by_seg  + ggtitle("Quality Controls Cutoffs Ciliated and Secretory segments comparison"))/
  
(qnorm_v_neg + ggtitle("Genes Detected by Segment")| 
   gene_segment_plot + ggtitle("Genes Detected by Segment") | 
   seq_v_area + ggtitle("Sequence saturation by area")| 
   tsne_day1_patient + ggtitle("tSNE plot (Day1 Segments)"))+
  
  
  plot_layout(heights = c(2, 1))+
  plot_annotation(tag_levels = 'A') & 
  theme(plot.tag = element_text(size = 16))



# 
# QC_metrics_by_day
# 
# QC_metrics_by_seg 
# qnorm_v_neg
# gene_segment_plot
# seq_v_area
# tsne_day1

```



Our collaborators used this dataset to perform gene expression analysis. The resulting differentially expressed genes are located in the analysis folder. 


